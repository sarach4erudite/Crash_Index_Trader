{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import ta \n",
    "from pyti import (relative_strength_index, \n",
    "                  chande_momentum_oscillator, \n",
    "                  weighted_moving_average,\n",
    "                  rate_of_change ,\n",
    "                  simple_moving_average,\n",
    "                  chaikin_money_flow,\n",
    "                  hull_moving_average,\n",
    "                  triangular_moving_average,\n",
    "                  volatility,\n",
    "                  commodity_channel_index)\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "\n",
    "try : \n",
    "    from keras.models import Sequential, model_from_json\n",
    "    from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM\n",
    "    from keras.callbacks import TensorBoard, EarlyStopping\n",
    "    from keras.metrics import categorical_accuracy, mae\n",
    "except : \n",
    "    from tensorflow.keras.models import Sequential, model_from_json\n",
    "    from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM\n",
    "    from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "    from tensorflow.keras.metrics import categorical_accuracy, mae\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/EURUSD_4H_NEW.csv')\n",
    "csv_result = \"Result/MyResult_CNN_EURUSD.csv\"\n",
    "\n",
    "shift_return = 5\n",
    "data['Return'] = data.Close.pct_change(shift_return).shift(-shift_return)\n",
    "data['Date'] = pd.to_datetime(data.Date)\n",
    "data['Year'] = data.Date.dt.year\n",
    "\n",
    "df_indicator = pd.DataFrame()  \n",
    "target = pd.DataFrame() \n",
    "df_indicator['Date'] = data.Date\n",
    "df_indicator['Year'] = data.Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Create Indicator ***\n",
      "1. Create RSI\n",
      "2. Create CMO\n",
      "3. Create WR\n",
      "4. Create MACD\n",
      "5. Create UO\n",
      "6. Create DPO\n",
      "7. Create EMA\n",
      "8. Create ROC\n",
      "9. Create SMA\n",
      "10. Create ATR\n"
     ]
    }
   ],
   "source": [
    "n_min = 14 \n",
    "n_max =  n_min+15\n",
    "print(\"*** Create Indicator ***\")\n",
    "print(\"1. Create RSI\")\n",
    "for i in range(n_min, n_max): \n",
    "    # RSI \n",
    "    df_indicator['RSI'+str(i)] = ta.rsi(data.Close, i)\n",
    "\n",
    "print(\"2. Create CMO\")\n",
    "for i in range(n_min, n_max): \n",
    "    # Chande Momentum Oscillator\n",
    "    df_indicator['CMO'+str(i)] = chande_momentum_oscillator.chande_momentum_oscillator(data.Close, i)\n",
    "\n",
    "print(\"3. Create WR\")\n",
    "for i in range(n_min, n_max): \n",
    "    # William %R \n",
    "    df_indicator['WR'+str(i)] = ta.wr(data.High, data.Low, data.Close,i)\n",
    "\n",
    "print(\"4. Create MACD\")\n",
    "for i in range(n_min, n_max):     \n",
    "    # MACD\n",
    "    df_indicator['MACD'+str(i)] = ta.macd(data.Close, i, i*2)\n",
    "\n",
    "print(\"5. Create UO\")\n",
    "for i in range(n_min, n_max): \n",
    "    # Weighted Moving Average\n",
    "    df_indicator['UO'+str(i)] = ta.momentum.uo(data.High, data.Low, data.Close, int(i/2), i, int(i*2))\n",
    "\n",
    "print(\"6. Create DPO\")\n",
    "for i in range(n_min, n_max): \n",
    "    # Detrended Price Oscillator\n",
    "    df_indicator['DPO'+str(i)] = ta.dpo(data.Close, i)\n",
    "\n",
    "print(\"7. Create EMA\")\n",
    "for i in range(n_min, n_max): \n",
    "    # EMA\n",
    "    df_indicator['EMA'+str(i)] = ta.ema(data.Close, i)\n",
    "\n",
    "print(\"8. Create ROC\")\n",
    "for i in range(n_min, n_max): \n",
    "    # ROC\n",
    "    df_indicator['ROC'+str(i)] = ta.trend.trix(data.Close, i)\n",
    "\n",
    "print(\"9. Create SMA\")\n",
    "for i in range(n_min, n_max):     \n",
    "    # SMA\n",
    "    df_indicator['SMA'+str(i)] = data.Close.rolling(i).mean()\n",
    "\n",
    "print(\"10. Create ATR\")\n",
    "for i in range(n_min, n_max): \n",
    "    # ATR\n",
    "    df_indicator['ATR'+str(i)] = ta.average_true_range(data.High, data.Low, data.Close, i)\n",
    "\n",
    "print(\"11. Create HMA\")\n",
    "for i in range(n_min, n_max):     \n",
    "    # HMA\n",
    "    df_indicator['HMA'+str(i)] = hull_moving_average.hull_moving_average(data.Close, i)\n",
    "\n",
    "print(\"12. Create ADX\")\n",
    "for i in range(n_min, n_max):     \n",
    "    # ADX \n",
    "    df_indicator['ADX'+str(i)] = ta.adx(data.High, data.Low, data.Close,i)\n",
    "\n",
    "print(\"13. Create TMA\")\n",
    "for i in range(n_min, n_max): \n",
    "    # TMA\n",
    "    df_indicator['TMA'+str(i)] = triangular_moving_average.triangular_moving_average(data.Close, i)\n",
    "\n",
    "print(\"14. Create VOL\")\n",
    "for i in range(n_min, n_max): \n",
    "    # Volatility\n",
    "    df_indicator['VOL'+str(i)] = data.Close.rolling(i).std()\n",
    "\n",
    "print(\"15. Create CCI\")\n",
    "for i in range(n_min, n_max): \n",
    "    # CCI \n",
    "    df_indicator['CCI'+str(i)] = ta.trend.cci(data.High, data.Low, data.Close,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_bound = {} \n",
    "class_num = 3\n",
    "class_range = 1/(class_num)\n",
    "\n",
    "print(\"Labeling Data ...\")\n",
    "for i in range(1,class_num+1):\n",
    "    if i != class_num : \n",
    "        class_bound[i] = data.Return.quantile(class_range*i)\n",
    "target = data[['Date','Year']]\n",
    "for i in range(class_num):  \n",
    "    if i == 0 :\n",
    "        data['Class_'+str(i)] = (data.Return <= class_bound[i+1]).astype(int)\n",
    "        target['Class_'+str(i)] = data['Class_'+str(i)]\n",
    "    elif i == class_num-1 : \n",
    "        data['Class_'+str(i)] = (data.Return > class_bound[i]).astype(int) \n",
    "        target['Class_'+str(i)] = data['Class_'+str(i)]\n",
    "    else : \n",
    "        data['Class_'+str(i)] = ((data.Return > class_bound[i]) & (data.Return <= class_bound[i+1])).astype(int)\n",
    "        target['Class_'+str(i)] = data['Class_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.Return.dropna(), bins='auto',color='blue')\n",
    "for i in range(1, class_num):    \n",
    "   plt.axvline(class_bound[i], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator = df_indicator[(df_indicator.Year >= 2014) & (df_indicator.Year <= 2018)]\n",
    "target = target[(target.Year >= 2014) & (target.Year <= 2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Divide Train/Test Set ... \")\n",
    "roll_over = 6*5*2\n",
    "train_length = int(len(df_indicator)*0.9)\n",
    "print(\"Train Start : \", df_indicator.Date.iloc[roll_over])\n",
    "print(\"Train End : \", df_indicator.Date.iloc[train_length-1])\n",
    "print(\"Test Start :\", df_indicator.Date.iloc[train_length])\n",
    "print(\"Test End :\", df_indicator.Date.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator.iloc[:train_length,2:].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_df_indicator = df_indicator\n",
    "sc = MinMaxScaler()\n",
    "sc.fit(df_indicator.iloc[:train_length,2:])\n",
    "scale_df_indicator.iloc[:,2:]= sc.transform(df_indicator.iloc[:,2:])\n",
    "scale_df_indicator.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = [] \n",
    "x_test = [] \n",
    "y_test = []\n",
    "start_index = roll_over\n",
    "\n",
    "predict_skip = 0 \n",
    "pure_image = None\n",
    "for i in range(len(scale_df_indicator)):\n",
    "    print(\"Image : \", i, \"/\", len(df_indicator)-1)\n",
    "    img_data = [] \n",
    "    for c in range(16, scale_df_indicator.shape[1], 15):\n",
    "        img_data.append(scale_df_indicator.iloc[i, c-15:c].values) \n",
    "#     print(img_data)\n",
    "    img_data = np.array(img_data)\n",
    "    pure_image = img_data\n",
    "    x_input = img_data\n",
    "    y_target = target.iloc[i,2:].values\n",
    "    if i < train_length :\n",
    "        x_train.append(x_input)\n",
    "        y_train.append(y_target)\n",
    "    else : \n",
    "        x_test.append(x_input)\n",
    "        y_test.append(y_target)\n",
    "\n",
    "x_train = np.array(x_train) \n",
    "x_test = np.array(x_test) \n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image = np.array(Image.fromarray(pure_image, 'L'))\n",
    "show_image = show_image\n",
    "show_image = (show_image-255)/255\n",
    "plt.imshow(show_image)\n",
    "show_image.shape\n",
    "# pure_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Output data\")\n",
    "y_train[-1], y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = np.reshape(x_train, x_train.shape + (1,)), np.reshape(x_test, x_test.shape + (1,))\n",
    "model_input_shape = (x_train.shape[1], x_train.shape[2], x_train.shape[3])\n",
    "model_input_shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, epochs=130):\n",
    "    tbCallBack = TensorBoard(log_dir='./Graph')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=epochs, validation_split=0.1, shuffle=False, callbacks=[tbCallBack, es])\n",
    "    # model.fit(x_train, y_train, batch_size=32, epochs=epochs, shuffle=True)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3,3, input_shape=model_input_shape, border_mode='same',activation='relu'))\n",
    "    model.add(Convolution2D(64, 3,3, activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.75))\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mse', metrics=[categorical_accuracy])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[categorical_accuracy])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name=''):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"Weight/\"+name+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"Weight/\"+name+\".h5\")\n",
    "        # serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(\"Weight/\"+name+\".yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "    # serialize weights to HDF5\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test, date=[], prices=[], init_profit=1):\n",
    "    p = model.predict(x_test)\n",
    "\n",
    "    true_class = [] \n",
    "    for i in range(len(y_test)):\n",
    "        true_class.append(np.argmax(y_test[i]))\n",
    "    pred_class = []     \n",
    "    for i in range(len(p)):\n",
    "        pred_class.append(np.argmax(p[i]))\n",
    "        \n",
    "    # true_class = pd.Series(true_class)\n",
    "    # pred_class = pd.Series(pred_class)\n",
    "    return pred_class, true_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input shape : \", model_input_shape)\n",
    "epoch = 1500\n",
    "\n",
    "print(\"Training model ...\")\n",
    "model_name = \"train_cnn_indicator_model\"\n",
    "model = init_model() \n",
    "model.summary()\n",
    "model = train_model(model, x_train, y_train, epochs=epoch)\n",
    "save_model(model, model_name)\n",
    "\n",
    "pred_class, true_class = test_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pred_class, true_class)\n",
    "plt.figure(figsize=(300,300))\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
